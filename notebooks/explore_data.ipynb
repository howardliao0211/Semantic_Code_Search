{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb1772d",
   "metadata": {},
   "source": [
    "Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b871de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9576b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and convert to dataframe\n",
    "ds = load_dataset(\"code_search_net\", \"python\", trust_remote_code=True)\n",
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# Retrieve necessary data series.\n",
    "df = df[['func_name', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d07345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 412178, 'test': 22176, 'validation': 23107}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in each set\n",
    "ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bef545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>func_code_tokens_len</th>\n",
       "      <th>func_documentation_tokens_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>WechatSogouAPI.__hosting_wechat_img</td>\n",
       "      <td>def __hosting_wechat_img(self, content_info, h...</td>\n",
       "      <td>[def, __hosting_wechat_img, (, self, ,, conten...</td>\n",
       "      <td>将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...</td>\n",
       "      <td>[将微信明细中图片托管到云端，同时将html页面中的对应图片替换]</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10984</th>\n",
       "      <td>WechatSogouAPI.get_article_content</td>\n",
       "      <td>def get_article_content(self, url, del_qqmusic...</td>\n",
       "      <td>[def, get_article_content, (, self, ,, url, ,,...</td>\n",
       "      <td>获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...</td>\n",
       "      <td>[获取文章原文，避免临时链接失效]</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>WechatSogouAPI.get_sugg</td>\n",
       "      <td>def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...</td>\n",
       "      <td>[def, get_sugg, (, self, ,, keyword, ), :, url...</td>\n",
       "      <td>获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...</td>\n",
       "      <td>[获取微信搜狗搜索关键词联想]</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>unlock_sogou_callback_example</td>\n",
       "      <td>def unlock_sogou_callback_example(url, req, re...</td>\n",
       "      <td>[def, unlock_sogou_callback_example, (, url, ,...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>unlock_weixin_callback_example</td>\n",
       "      <td>def unlock_weixin_callback_example(url, req, r...</td>\n",
       "      <td>[def, unlock_weixin_callback_example, (, url, ...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 func_name  \\\n",
       "10978  WechatSogouAPI.__hosting_wechat_img   \n",
       "10984   WechatSogouAPI.get_article_content   \n",
       "10985              WechatSogouAPI.get_sugg   \n",
       "10986        unlock_sogou_callback_example   \n",
       "10987       unlock_weixin_callback_example   \n",
       "\n",
       "                                        func_code_string  \\\n",
       "10978  def __hosting_wechat_img(self, content_info, h...   \n",
       "10984  def get_article_content(self, url, del_qqmusic...   \n",
       "10985  def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...   \n",
       "10986  def unlock_sogou_callback_example(url, req, re...   \n",
       "10987  def unlock_weixin_callback_example(url, req, r...   \n",
       "\n",
       "                                        func_code_tokens  \\\n",
       "10978  [def, __hosting_wechat_img, (, self, ,, conten...   \n",
       "10984  [def, get_article_content, (, self, ,, url, ,,...   \n",
       "10985  [def, get_sugg, (, self, ,, keyword, ), :, url...   \n",
       "10986  [def, unlock_sogou_callback_example, (, url, ,...   \n",
       "10987  [def, unlock_weixin_callback_example, (, url, ...   \n",
       "\n",
       "                               func_documentation_string  \\\n",
       "10978  将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...   \n",
       "10984  获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...   \n",
       "10985  获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...   \n",
       "10986  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "10987  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "\n",
       "               func_documentation_tokens  func_code_tokens_len  \\\n",
       "10978  [将微信明细中图片托管到云端，同时将html页面中的对应图片替换]                    83   \n",
       "10984                  [获取文章原文，避免临时链接失效]                   116   \n",
       "10985                    [获取微信搜狗搜索关键词联想]                    71   \n",
       "10986                           [手动打码解锁]                   112   \n",
       "10987                           [手动打码解锁]                    97   \n",
       "\n",
       "       func_documentation_tokens_len  \n",
       "10978                              1  \n",
       "10984                              1  \n",
       "10985                              1  \n",
       "10986                              1  \n",
       "10987                              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the length of code token and docstring token\n",
    "df['func_code_tokens_len'] = df['func_code_tokens'].apply(lambda x: len(x))\n",
    "df['func_documentation_tokens_len'] = df['func_documentation_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "df['func_code_tokens_len'].describe(), df['func_documentation_tokens_len'].describe()\n",
    "\n",
    "# There are chinese documentation...\n",
    "df.loc[df['func_documentation_tokens_len'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5917652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_dataset(ds, min_doc_token: int, max_doc_token: int, min_code_token: int, max_code_token: int, language='python') -> bool:\n",
    "    # Step 1: Only allow python\n",
    "    if ds['language'] != language:\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Check if the coden token length if > min_code_token\n",
    "    if len(ds['func_code_tokens']) < min_code_token or \\\n",
    "        len(ds['func_code_tokens']) > max_code_token:\n",
    "        return False\n",
    "    \n",
    "    if len(ds['func_documentation_tokens']) < min_doc_token or \\\n",
    "        len(ds['func_documentation_tokens']) > max_doc_token:\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Check if the func documentation only include ascii code (exclude non-english).\n",
    "    if ds['func_documentation_string'].isascii() == False:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def _filter_columns_from_dataset(datasets, columns_to_save: list):\n",
    "\n",
    "    # Get all the columns names\n",
    "    dataset_columns_to_remove = {\n",
    "        dataset: columns for dataset, columns in datasets.column_names.items()\n",
    "    }\n",
    "\n",
    "    # Remove columns to save from all the column names\n",
    "    for dataset in dataset_columns_to_remove:\n",
    "        for column in columns_to_save:\n",
    "            if column in dataset_columns_to_remove[dataset]:\n",
    "                dataset_columns_to_remove[dataset].remove(column)\n",
    "\n",
    "    # Remove all the columns except columns_to_save.\n",
    "    for dataset in datasets:\n",
    "        datasets[dataset] = datasets[dataset].remove_columns(dataset_columns_to_remove[dataset])\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "columns_to_save = [\n",
    "        'func_code_string',\n",
    "        'func_code_tokens',\n",
    "        'func_documentation_string',\n",
    "        'func_documentation_tokens'\n",
    "    ]\n",
    "\n",
    "filtered_ds = ds.filter(lambda example: _filter_dataset(example, 0, 64, 0, 64))\n",
    "filtered_ds = _filter_columns_from_dataset(ds, columns_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ad6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 412178/412178 [00:37<00:00, 11085.98 examples/s]\n",
      "Map: 100%|██████████| 22176/22176 [00:02<00:00, 10623.71 examples/s]\n",
      "Map: 100%|██████████| 23107/23107 [00:02<00:00, 10287.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def _unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def _normalize_string(s):\n",
    "    s = _unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def preprocess_documentation_string_to_tokens(s):\n",
    "    return _normalize_string(s).split()\n",
    "\n",
    "filtered_ds = filtered_ds.map(\n",
    "    lambda example: {\n",
    "        'func_documentation_tokens': preprocess_documentation_string_to_tokens(example['func_documentation_string'])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f43d459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[trains, a, k, nearest, neighbors, classifier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[recognizes, faces, in, given, image, using, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[shows, the, face, recognition, results, visua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[make, sure, a, tuple, in, top, right, bottom,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    func_code_string  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                           func_documentation_tokens  \n",
       "0  [trains, a, k, nearest, neighbors, classifier,...  \n",
       "1  [recognizes, faces, in, given, image, using, a...  \n",
       "2  [shows, the, face, recognition, results, visua...  \n",
       "3  [convert, a, dlib, rect, object, to, a, plain,...  \n",
       "4  [make, sure, a, tuple, in, top, right, bottom,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pd = filtered_ds['train'].to_pandas()\n",
    "filtered_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de18fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code tokens: 8192\n",
      "doc tokens: 8192\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Code\\Code_Semantic_Search')\n",
    "\n",
    "from data.tokenizer import Tokenizer\n",
    "code_tokenizer = Tokenizer(8192)\n",
    "doc_tokenizer = Tokenizer(8192)\n",
    "\n",
    "# Load tokens in tokenizer\n",
    "code_tokenizer.load_datasets(filtered_ds, 'func_code_tokens')\n",
    "doc_tokenizer.load_datasets(filtered_ds, 'func_documentation_tokens')\n",
    "print(f'code tokens: {len(code_tokenizer)}')\n",
    "print(f'doc tokens: {len(doc_tokenizer)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532179d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 412178/412178 [00:51<00:00, 8005.37 examples/s]\n",
      "Filter: 100%|██████████| 22176/22176 [00:02<00:00, 8164.58 examples/s]\n",
      "Filter: 100%|██████████| 23107/23107 [00:03<00:00, 7561.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# filter the dataset to only include allow code tokens and allow documentation tokens\n",
    "# so that the dataset will not have any unknown token\n",
    "def _filter_tokens(ds, allow_code_tokens, allow_doc_tokens) -> bool:\n",
    "    for code_token, doc_token in zip(ds['func_code_tokens'], ds['func_documentation_tokens']):\n",
    "        if code_token not in allow_code_tokens:\n",
    "            return False\n",
    "\n",
    "        if doc_token not in allow_doc_tokens:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "filtered_tokens = filtered_ds.filter(lambda example: _filter_tokens(example, code_tokenizer.most_freq_tokens, doc_tokenizer.most_freq_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a08acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37671, 2049, 2401)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_tokens['train']), len(filtered_tokens['test']), len(filtered_tokens['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8534e",
   "metadata": {},
   "source": [
    "# Examine documentation classes for applying class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32787a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed dataset...\n",
      "Train Dataset Size: 25347\n",
      "Test Dataset Size: 1398\n",
      "Validation Dataset Size: 1286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word\n",
       "the            532151\n",
       "a              254480\n",
       "to             223267\n",
       "of             212582\n",
       "param          115704\n",
       "                ...  \n",
       "xb                 36\n",
       "disabling          36\n",
       "lightweight        36\n",
       "emulates           36\n",
       "tempdir            36\n",
       "Name: count, Length: 8188, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(r'C:\\Code\\Code_Semantic_Search')\n",
    "\n",
    "from pathlib import Path\n",
    "from data.dataset import get_datasets\n",
    "from data.tokenizer import Tokenizer\n",
    "\n",
    "# Configure hyperparameters\n",
    "input_size = 8192\n",
    "output_size = 8192\n",
    "batch_size = 64\n",
    "hidden_size = 256\n",
    "sequence_length = 128\n",
    "dropout_p = 0.3\n",
    "weight_decay = 1e-5\n",
    "learning_rate = 5e-4\n",
    "label_smoothing = 0.1\n",
    "\n",
    "# Get datasets\n",
    "DATASET_LOCAL_PATH = Path(r'C:\\Code\\Code_Semantic_Search\\preprocessed_dataset')\n",
    "code_tokenizer = Tokenizer(input_size)\n",
    "doc_tokenizer = Tokenizer(output_size)\n",
    "train_dataset, test_dataset, validation_dataset = get_datasets(data_local_path=DATASET_LOCAL_PATH,\n",
    "                                                    code_tokenizer=code_tokenizer,\n",
    "                                                    doc_tokenizer=doc_tokenizer,\n",
    "                                                    sequence_length=sequence_length)\n",
    "\n",
    "doc_freq = {\n",
    "    'word': [],\n",
    "}\n",
    "\n",
    "# Create a dictionary with a list of tokens\n",
    "for word, freq in doc_tokenizer.counter.items():\n",
    "    if word in doc_tokenizer.most_freq_tokens:\n",
    "        doc_freq['word'] += [word] * freq\n",
    "\n",
    "doc_df = pd.DataFrame.from_dict(doc_freq)\n",
    "doc_df['word'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0418ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,  22.,  40.,  98., 179., 237., 315., 314., 370., 427., 475.,\n",
       "        455., 498., 544., 569., 521., 546., 543., 613., 603., 619., 196.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          3.]),\n",
       " array([4.54753172e-05, 5.10163445e-05, 5.65573682e-05, 6.20983919e-05,\n",
       "        6.76394193e-05, 7.31804466e-05, 7.87214667e-05, 8.42624941e-05,\n",
       "        8.98035214e-05, 9.53445488e-05, 1.00885576e-04, 1.06426596e-04,\n",
       "        1.11967624e-04, 1.17508651e-04, 1.23049671e-04, 1.28590706e-04,\n",
       "        1.34131726e-04, 1.39672746e-04, 1.45213780e-04, 1.50754800e-04,\n",
       "        1.56295835e-04, 1.61836855e-04, 1.67377875e-04, 1.72918910e-04,\n",
       "        1.78459930e-04, 1.84000950e-04, 1.89541985e-04, 1.95083005e-04,\n",
       "        2.00624025e-04, 2.06165059e-04, 2.11706079e-04, 2.17247114e-04,\n",
       "        2.22788134e-04, 2.28329154e-04, 2.33870189e-04, 2.39411209e-04,\n",
       "        2.44952244e-04, 2.50493264e-04, 2.56034284e-04, 2.61575333e-04,\n",
       "        2.67116353e-04, 2.72657373e-04, 2.78198393e-04, 2.83739413e-04,\n",
       "        2.89280433e-04, 2.94821453e-04, 3.00362502e-04, 3.05903523e-04,\n",
       "        3.11444543e-04, 3.16985563e-04, 3.22526583e-04, 3.28067632e-04,\n",
       "        3.33608652e-04, 3.39149672e-04, 3.44690692e-04, 3.50231712e-04,\n",
       "        3.55772732e-04, 3.61313781e-04, 3.66854802e-04, 3.72395822e-04,\n",
       "        3.77936842e-04, 3.83477862e-04, 3.89018911e-04, 3.94559931e-04,\n",
       "        4.00100951e-04, 4.05641971e-04, 4.11182991e-04, 4.16724040e-04,\n",
       "        4.22265060e-04, 4.27806081e-04, 4.33347101e-04, 4.38888121e-04,\n",
       "        4.44429170e-04, 4.49970190e-04, 4.55511210e-04, 4.61052230e-04,\n",
       "        4.66593250e-04, 4.72134270e-04, 4.77675319e-04, 4.83216339e-04,\n",
       "        4.88757389e-04, 4.94298409e-04, 4.99839429e-04, 5.05380449e-04,\n",
       "        5.10921469e-04, 5.16462489e-04, 5.22003509e-04, 5.27544529e-04,\n",
       "        5.33085549e-04, 5.38626569e-04, 5.44167589e-04, 5.49708668e-04,\n",
       "        5.55249688e-04, 5.60790708e-04, 5.66331728e-04, 5.71872748e-04,\n",
       "        5.77413768e-04, 5.82954788e-04, 5.88495808e-04, 5.94036828e-04,\n",
       "        5.99577848e-04]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_class_weight_vector(tokenizer: Tokenizer, smoothing: float=0.5) -> torch.Tensor:\n",
    "    num_of_class = len(tokenizer)\n",
    "    weight_vector = torch.ones(num_of_class, dtype=torch.float)\n",
    "    \n",
    "    for word, count in tokenizer.counter.items():\n",
    "        idx = tokenizer.to_idx(word)\n",
    "        # min_count = 1e-6 # to prevent zero division\n",
    "        # weight_vector[idx] = 1.0 / ((count + min_count) ** smoothing) # Power\n",
    "        weight_vector[idx] = 1.0 / math.log(count + math.e)\n",
    "    \n",
    "    return weight_vector / weight_vector.sum() # normalize weight\n",
    "\n",
    "weight_vector = get_class_weight_vector(doc_tokenizer)\n",
    "plt.hist(weight_vector.numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283ca852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "path_to_zip_file = r'../data/Cleaned_CodeSearchNet.zip'\n",
    "directory_to_extract_to = r'../data'\n",
    "\n",
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class Example:\n",
    "    \"\"\"A single training/test example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 idx,\n",
    "                 source,\n",
    "                 target,\n",
    "                 ):\n",
    "        self.idx = idx\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "\n",
    "def read_examples(filename) -> List[Example]:\n",
    "    \"\"\"Read examples from filename.\"\"\"\n",
    "    examples=[]\n",
    "    with open(filename,encoding=\"utf-8\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line=line.strip()\n",
    "            js=json.loads(line)\n",
    "            if 'idx' not in js:\n",
    "                js['idx']=idx\n",
    "            code=' '.join(js['code_tokens']).replace('\\n',' ')\n",
    "            code=' '.join(code.strip().split())\n",
    "            nl=' '.join(js['docstring_tokens']).replace('\\n','')\n",
    "            nl=' '.join(nl.strip().split())\n",
    "            examples.append(\n",
    "                Example(\n",
    "                        idx = idx,\n",
    "                        source=code,\n",
    "                        target = nl,\n",
    "                        ) \n",
    "            )\n",
    "    return examples\n",
    "\n",
    "trains = read_examples(r'..\\data\\CodeSearchNet\\python\\train.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f301ee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def split_phylogeny ( p , level = \"s\" ) : level = level + \"__\" result = p . split ( level ) return result [ 0 ] + level + result [ 1 ] . split ( \";\" ) [ 0 ]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains[0].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40c446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
